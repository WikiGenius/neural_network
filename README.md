# Neural Network From Scratch

## The purpose of this project

is to implement the magical NN from scratch by applying some math like linear algebra, calculus, and probabilities.
And understanding the hyperparameters and implementing various techniques to improve the learning process.

```python
python train.py
```

## Inventory

Customize n hidden layers as you want to make it deep

Customize the number of neurons in each hidden layer

Flexibility Adding bias or not for all layers

Early stopping algorithm

Flexibility adding drop out for the layers

regularization L1 / regularization L2

Flavors gradient descent:
    Batch gradient descent
    Stocastic gradient descent
    Mini batch gradient descent

Implemintig common activation function: Sigmoid / Softmax / tanh /relu /elu

Plot nonlinear boundaries for 2 dimensions

Add Momentum

-------------------------------------------------------------------------------------

-------------------------------------------------------------------------------------

### My account

muhammedelyamani92@gmail.com

[Github](https://github.com/WikiGenius)

-------------------------------------------------------------------------------------

## The project under development

Keep updated
